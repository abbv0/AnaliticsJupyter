{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42058087-1665-4cc0-a479-d097bb817050",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'(' was never closed (2793691028.py, line 100)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 100\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(df['max_floor'].unique\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m '(' was never closed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # Импорт библиотеки для работы с данными в формате таблицы (DataFrame)\n",
    "import numpy as np  # Импорт библиотеки для работы с числовыми данными\n",
    "import seaborn as sns  # Импорт библиотеки для визуализации данных\n",
    "import matplotlib.pyplot as plt  # Импорт библиотеки для построения графиков\n",
    "import matplotlib.mlab as mlab  # Импорт библиотеки для работы с графиками\n",
    "import matplotlib  # Импорт основной библиотеки для работы с графиками\n",
    "plt.style.use('ggplot')  # Задание стиля графиков\n",
    "%matplotlib inline  # Встроенная магическая команда для отображения графиков в Jupyter Notebook\n",
    "matplotlib.rcParams['figure.figsize'] = (10,10)  # Задание размеров графиков\n",
    "pd.options.mode.chained_assignment = None  # Отключение предупреждений о цепочечных присваиваниях\n",
    "from sklearn.model_selection import train_test_split as tts  # Импорт функции для разделения данных на обучающую и тестовую выборки\n",
    "from sklearn.ensemble import ExtraTreesClassifier  # Импорт класса для построения модели на основе деревьев\n",
    "from sklearn.ensemble import GradientBoostingRegressor  # Импорт класса для построения градиентного бустинга\n",
    "from sklearn.metrics import mean_absolute_error as mae, r2_score, mean_squared_error as mse  # Импорт метрик для оценки качества модели\n",
    "from sklearn.pipeline import Pipeline  # Импорт класса для создания пайплайна обработки данных\n",
    "from sklearn.compose import ColumnTransformer  # Импорт класса для преобразования данных по столбцам\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler  # Импорт классов для кодирования категориальных признаков и масштабирования числовых\n",
    "from sklearn.impute import SimpleImputer  # Импорт класса для заполнения пропущенных значений в данных\n",
    "\n",
    "# Скачиваем, записываем и просматриваем данные файлов.\n",
    "train = pd.read_csv('train.csv')\n",
    "display(train)\n",
    "\n",
    "macro = pd.read_csv('macro.csv')\n",
    "display(macro)\n",
    "macro['timestamp'].describe()\n",
    "\n",
    "# Объединяем датафреймы по времени.\n",
    "macro['timestamp'] = pd.to_datetime(macro['timestamp'])\n",
    "train['timestamp'] = pd.to_datetime(train['timestamp'])\n",
    "df = pd.merge(train, macro, on='timestamp')\n",
    "display(df)\n",
    "\n",
    "# Поиск категориальных признаков\n",
    "i = 0\n",
    "for column in df.select_dtypes(include='object'):\n",
    "    i = i + 1\n",
    "    print(i)\n",
    "    print(column)\n",
    "    print('Uniq values:', df[column].nunique())\n",
    "    print(df[column].unique())\n",
    "\n",
    "# Присваивание числовых значений категориальным столбцам.\n",
    "pt = {'Investment': 1, 'OwnerOccupier': 0}\n",
    "df['product_type'] = df['product_type'].map(pt)\n",
    "\n",
    "ec = {'poor': 1, 'satisfactory': 2, 'good': 3, 'excellent': 4, 'no data': np.nan}\n",
    "df['ecology'] = df['ecology'].map(ec)\n",
    "\n",
    "df['child_on_acc_pre_school'] = df['child_on_acc_pre_school'].replace('#!', np.nan)\n",
    "\n",
    "cmo = ['child_on_acc_pre_school', 'modern_education_share', 'old_education_build_share']\n",
    "\n",
    "# Замена запятых на точки и преобразование строк в числа с плавающей запятой.\n",
    "for column in cmo:\n",
    "    df[column] = df[column].str.replace(',', '.').astype(float)\n",
    "\n",
    "# Преобразование бинарных столбцов в числовой формат.\n",
    "bin_cols = ['culture_objects_top_25',\n",
    "            'thermal_power_plant_raion',\n",
    "            'incineration_raion',\n",
    "            'oil_chemistry_raion',\n",
    "            'radiation_raion',\n",
    "            'railroad_terminal_raion',\n",
    "            'big_market_raion',\n",
    "            'nuclear_reactor_raion',\n",
    "            'detention_facility_raion',\n",
    "            'water_1line',\n",
    "            'big_road1_1line',\n",
    "            'railroad_1line']\n",
    "df[bin_cols] = df[bin_cols].applymap(lambda x: 1 if x == 'yes' else 0)\n",
    "\n",
    "# Создание нового столбца с объединением редких значений.\n",
    "suba = (df['sub_area'].value_counts() >= 100).loc[lambda x: x == True].index.tolist()\n",
    "df['sub_area_new'] = np.where(df['sub_area'].isin(suba), df['sub_area'], 'Other')\n",
    "df['sub_area_new'].value_counts()\n",
    "\n",
    "# Вывод информации до и после объединения значений в столбце 'sub_area'.\n",
    "print('До объединения -\\n', df['sub_area'].value_counts())\n",
    "print('\\nПосле объединения -\\n', df['sub_area_new'].value_counts())\n",
    "\n",
    "# Удаление столбца 'sub_area'.\n",
    "df = df.drop('sub_area', axis=1)\n",
    "\n",
    "# Поиск аномалий и замена значений в столбце 'state'.\n",
    "print(df['state'].value_counts())\n",
    "df['state'].replace(33, 3, inplace=True)\n",
    "print(df['state'].value_counts())\n",
    "\n",
    "# Замена значений в столбце 'build_year'.\n",
    "print(df['build_year'].value_counts())\n",
    "bld_yr_replace = {20052009: 2009, 0: np.nan, 1: np.nan, 2: np.nan, 3: np.nan, 20: 2020, 215: 2015, 4965: 1965, 71: 1971}\n",
    "df['build_year'].replace(bld_yr_replace, inplace=True)\n",
    "print(df['build_year'].value_counts())\n",
    "\n",
    "# Замена значений в столбце 'max_floor'.\n",
    "print(df['max_floor'].unique())\n",
    "max_flr_replace = {117: 17, 99: np.nan, 0: np.nan}\n",
    "df['max_floor'].replace(max_flr_replace, inplace=True)\n",
    "print(df['max_floor'].unique\n",
    "\n",
    "# Замена значений в столбце 'full_sq'.\n",
    "full_sq_replace = {5326: np.nan, 0: np.nan}\n",
    "df['full_sq'].replace(full_sq_replace, inplace=True)\n",
    "print(df['full_sq'].unique())\n",
    "\n",
    "# Удаление неинформативных признаков.\n",
    "df = df.drop(['id',\n",
    "              'ID_big_road1',\n",
    "              'ID_big_road2',\n",
    "              'ID_bus_terminal',\n",
    "              'ID_metro',\n",
    "              'ID_railroad_station_avto',\n",
    "              'ID_railroad_station_walk',\n",
    "              'ID_railroad_terminal'], axis=1)\n",
    "\n",
    "# Поиск пропусков цены и дупликатов, удаление.\n",
    "print('Количество пропусков цены -', df['price_doc'].isna().sum())\n",
    "print('Количество дупликатов -', df.duplicated().sum())\n",
    "df = df.drop_duplicates()\n",
    "print('Теперь дупликатов -', df.duplicated().sum())\n",
    "\n",
    "# Удаляем признаки, которые заполнены менее чем на 55 процентов (уровень пропусков выше 45%).\n",
    "i = 0\n",
    "for col in df.columns:\n",
    "    pct_missing = np.mean(df[col].isnull())\n",
    "    if pct_missing * 100 > 45:\n",
    "        df.drop([str(col)], axis=1, inplace=True)\n",
    "\n",
    "# Вывод процента пропущенных значений для каждого признака.\n",
    "for col in df.columns:\n",
    "    pct_missing = np.mean(df[col].isnull())\n",
    "    print('{} - {}%'.format(col, round(pct_missing * 100)))\n",
    "    i = i + 1\n",
    "    print(i)\n",
    "\n",
    "# Создаем индикатор для строк с пропущенными данными.\n",
    "for col in df.columns:\n",
    "    missing = df[col].isnull()\n",
    "    num_missing = np.sum(missing)\n",
    "\n",
    "    if num_missing > 0:\n",
    "        print('created missing indicator for: {}'.format(col))\n",
    "        df['{}_ismissing'.format(col)] = missing\n",
    "\n",
    "# Формируем список колонок с индикаторами пропущенных значений.\n",
    "ismissing_cols = [col for col in df.columns if 'ismissing' in col]\n",
    "df['num_missing'] = df[ismissing_cols].sum(axis=1)\n",
    "display(df)\n",
    "\n",
    "# Удаляем строки с большим количеством пропусков (больше 35).\n",
    "ind_missing = df[df['num_missing'] > 35].index\n",
    "df.drop(ind_missing, axis=0, inplace=True)\n",
    "display(df)\n",
    "\n",
    "df_new = df.select_dtypes(include=[np.number]): Выбирает только числовые столбцы из исходного DataFrame df и сохраняет результат в новый DataFrame df_new.\n",
    "\n",
    "df_new = df_new.dropna(): Удаляет строки с пропущенными значениями из нового DataFrame df_new.\n",
    "\n",
    "df_new['price_doc_right'] = df_new['price_doc']: #Создает новый столбец 'price_doc_right', который является копией столбца 'price_doc'.\n",
    "\n",
    "df_new.drop('price_doc', axis=1, inplace=True): #Удаляет столбец 'price_doc' из DataFrame df_new.\n",
    "\n",
    "array = df_new.values: #Преобразует DataFrame df_new в массив NumPy.\n",
    "\n",
    "X = array[:,0:373]: Выделяет все строки и первые 373 столбца массива array и сохраняет их в переменной X. Это матрица признаков.\n",
    "\n",
    "Y = array[:,373]: Выделяет все строки и последний столбец массива array и сохраняет его в переменной Y. Это вектор целевой переменной.\n",
    "\n",
    "model = ExtraTreesClassifier(): Создает экземпляр класса ExtraTreesClassifier, который представляет собой модель на основе деревьев решений для задачи классификации.\n",
    "\n",
    "model.fit(X, Y): Обучает модель на матрице признаков X и векторе целевой переменной Y.\n",
    "\n",
    "print(model.feature_importances_): Выводит важности признаков, рассчитанные моделью. Каждый элемент этого массива представляет собой важность соответствующего признака.\n",
    "\n",
    "Таким образом, код использует алгоритм Extra Trees (экстремальные деревья) для определения важности признаков в данных и выводит результаты на экран. Важности признаков представлены в виде массива чисел, где каждое число отражает вклад соответствующего признака в обучение модели.\n",
    "\n",
    "# 10 самых влияющих на цену недвижимости признаков.\n",
    "tree_df = pd.DataFrame(data=model.feature_importances_, index=[list(range(1, 374))])\n",
    "tree_df.sort_values(0, ascending=False).head(10)\n",
    "\n",
    "# Корреляция цены на недвижимость в зависимости от жилплощади.\n",
    "agg = df_new.groupby('full_sq')['price_doc_right'].mean()\n",
    "agg.plot()\n",
    "\n",
    "# Корреляция цены на недвижимость в зависимости от даты.\n",
    "agg2 = df.groupby('timestamp')['price_doc'].mean()\n",
    "agg2.plot()\n",
    "\n",
    "# Какая цена на недвижимость встречается чаще.\n",
    "df['price_doc'].hist(bins=100)\n",
    "\n",
    "# Разделение датасета на обучающую и тестовую выборку с помощью train_test_split.\n",
    "X_new = df.copy()\n",
    "X_new = X_new[X_new.select_dtypes(include='number').columns]\n",
    "X_new = X_new.dropna()\n",
    "Y_new = np.array(X_new['price_doc'])\n",
    "X_new = X_new.drop('price_doc', axis=1)\n",
    "\n",
    "X_train0, X_test0, Y_train0, Y_test0 = tts(X_new, Y_new, test_size=0.2, shuffle=True)\n",
    "\n",
    "# Обучение регрессионной модели с помощью GradientBoostingRegressor.\n",
    "regress = GradientBoostingRegressor()\n",
    "regress.fit(X_train0, Y_train0)\n",
    "\n",
    "Y_train_pred0 = regress.predict(X_train0)\n",
    "Y_test_pred0 = regress.predict(X_test0)\n",
    "\n",
    "# Вывод метрик качества модели.\n",
    "print('Train MAE', mae(Y_train0, Y_train_pred0), ' ', 'Test MAE:', mae(Y_test0, Y_test_pred0))\n",
    "print('Train MSE', mse(Y_train0, Y_train_pred0), ' ', 'Test MSE:', mse(Y_test0, Y_test_pred0))\n",
    "print('Train R2', r2_score(Y_train0, Y_train_pred0), ' ', 'Test R2:', r2_score(Y_test0, Y_test_pred0))\n",
    "\n",
    "# Создаем новые фичи по признаку timestamp.\n",
    "df['month'] = (df['timestamp'].dt.to_period('M'))\n",
    "df['dow'] = df['timestamp'].dt.dayofweek\n",
    "df['dom'] = df['timestamp'].dt.day\n",
    "df['doy'] = df['timestamp'].dt.dayofyear\n",
    "df['month'] = df['timestamp'].dt.month\n",
    "df = df.drop('timestamp', axis=1)\n",
    "\n",
    "# Разделение датасета на обучающую и тестовую выборку с помощью train_test_split.\n",
    "X = df.copy()\n",
    "Y = X.pop('price_doc')\n",
    "X_train, X_test, Y_train, Y_test = tts(X, Y, test_size=0.2, stratify=X['sub_area_new'], shuffle=True)\n",
    "\n",
    "# Объявление и подготовка к реализации новых фич.\n",
    "features1 = ['sub_area_new']\n",
    "features2 = ['thermal_power_plant_raion', 'incineration_raion', 'oil_chemistry_raion', 'radiation_raion',\n",
    "             'railroad_terminal_raion', 'big_market_raion', 'nuclear_reactor_raion', 'detention_facility_raion',\n",
    "             'water_1line', 'big_road1_1line', 'railroad_1line', 'railroad_1line', 'product_type', 'ecology',\n",
    "             'material', 'state', 'month', 'dow', 'dom', 'doy', 'month']\n",
    "\n",
    "features = features1 + features2\n",
    "\n",
    "list_features =list(set(X_train.columns.tolist()) - set(features))\n",
    "\n",
    "# Подготовка к реализации новых фич.\n",
    "X_train_trans = X_train.copy()\n",
    "X_test_trans = X_test.copy()\n",
    "\n",
    "# Преобразование категориальных признаков.\n",
    "categorial_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                                         ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))])\n",
    "\n",
    "# Заполнение пропущенных значений для числовых признаков и их масштабирование.\n",
    "imputer_scaler_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
    "                                             ('scaler', MinMaxScaler())])\n",
    "\n",
    "# Применение преобразований к различным группам признаков.\n",
    "preprocessor = ColumnTransformer(transformers=[('categorical', categorial_transformer, features1),\n",
    "                                               ('imputer_scaler', imputer_scaler_transformer, features2),\n",
    "                                               ('passthrough', 'passthrough', list_features)])\n",
    "\n",
    "# Построение пайплайна с преобразованием данных и обучением модели.\n",
    "reg = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('regressor', GradientBoostingRegressor())])\n",
    "\n",
    "# Обучение модели на обучающей выборке.\n",
    "reg.fit(X_train_trans, Y_train)\n",
    "\n",
    "# Прогнозы для обучающей и тестовой выборок.\n",
    "Y_train_pred = reg.predict(X_train_trans)\n",
    "Y_test_pred = reg.predict(X_test_trans)\n",
    "\n",
    "# Вывод метрик качества новой модели.\n",
    "print('Train MAE:', mae(Y_train, Y_train_pred), 'Test MAE:', mae(Y_test, Y_test_pred))\n",
    "print('Train MSE:', mse(Y_train, Y_train_pred), 'Test MSE:', mse(Y_test, Y_test_pred))\n",
    "print('Train R2:', r2_score(Y_train, Y_train_pred), 'Test R2:', r2_score(Y_test, Y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a9c8ab-046b-4fc2-ad8a-9e70f87f864d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
